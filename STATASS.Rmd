---
title: "STAT5003Assignment1"
author: "Group 10"
date: "26/04/2019"
output: html_document
---

---
title: "STAT5003 Assignment1"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
### Initialize
```{r}
library(ggplot2)
theme_update(plot.title = element_text(hjust = 0.5))

# Multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
```

## Exploratory data analysis
### Data Cleaning
#### DonorInfo data
1. Load DonorInfo and drop columns

```{r}
DonorInfo <- read.csv("DonorInformation.csv", header = TRUE, sep = ",", encoding = "UTF-8")
DonorInfo.clean <- DonorInfo[c('donor_id', 'age', 'sex', 'apo_e4_allele', 'education_years', 'age_at_first_tbi', 'num_tbi_w_loc', 'act_demented')]

dim(DonorInfo.clean)
summary(DonorInfo.clean)

ggplot()+geom_histogram(data=data.frame(x=DonorInfo$age_at_first_tbi), bins = 20, aes(x)) + labs(title="Histogram of Age at first TBI", x ="Age at first TBI", y = "Population")
```

2. Deal with N/A and categorical features
age, sex, apo_e4_allele, education_years, age_at_first_tbi, longest_loc_duration, num_tbi_w_loc

Categorical features:
Age: Linear from ages 72-89; binned at 90-94, 95-99, and 100+.
Sex: Gender
apo_e4_allele: Yes - at least one ApoE4 allele; No - no ApoE4 allele present
longest_loc_duration: Ordinal score of length of loss of consciousness: 0 (none or unknown), 1 (a few sec or <), 2 (min or <), 3 (1-2 min), 4 (3-5 min), 5 (6-9 min), 6 (10 min-1 hr), and 7 (> 1 hr).

Numerical features:
education_years: Number of years of education completed
age_at_first_tbi: Age at which first TBI with loss of consciousness was reported.
num_tbi_w_loc: Number of recorded TBI, ranging from 0 (control) to 3.

```{r}
#clean age
summary(DonorInfo$age)
age <- as.character(DonorInfo$age) 
age[DonorInfo$age=='90-94'] <- 92
age[DonorInfo$age=='95-99'] <- 97
age[DonorInfo$age=='100+'] <- 100
age <- as.numeric(age)

ggplot()+geom_histogram(data=data.frame(x=age), bins = 20, aes(x)) + labs(title="Histogram of age", x ="Age", y = "Population")
summary(age)
DonorInfo.clean$age <- age

#clean apo_e4_allele
summary(DonorInfo$apo_e4_allele)
apo_e4_allele <- as.numeric(DonorInfo$apo_e4_allele)-1
#0->N 1->N/A 2->Y
#all N/A to N
apo_e4_allele[apo_e4_allele==1] <- 0
apo_e4_allele[apo_e4_allele==2] <- 1
DonorInfo.clean$apo_e4_allele <- apo_e4_allele

DonorInfo.clean$sex <- as.numeric(DonorInfo$sex)-1
DonorInfo.clean$act_demented <- as.numeric(DonorInfo$act_demented)-1

```

3. Check cleaned donor data information. Every feature is numerical. 

```{r}
summary(DonorInfo.clean)
```

4. create 10 fold cross validation based on patients and append the cross fold validation as a column in the dataframe for merging purposes. The integer number from 1 to 10 represents its correpsonding cross validation group of the row. 

```{r}
library(caret)
fold <- createFolds(DonorInfo.clean$act_demented, k=10)
cv = rep(0,length(DonorInfo.clean$act_demented))
for (i in 1:10) {
  cv[fold[[i]]] = i
}
DonorInfo.clean['cv'] = cv
table(DonorInfo.clean$cv)
```


#### ProteinInfo data
1. Load ProteinInfo and remove redundant columns including donor_name and structure_acronym.

```{r}
ProteinInfo.raw <- read.csv("ProteinAndPathologyQuantifications.csv", header = TRUE, sep = ",", encoding = "UTF-8")
head(ProteinInfo.raw)
ProteinInfo <- ProteinInfo.raw[,c(-2,-4)]
head(ProteinInfo)
```

2. Check how many NAs are present in the Protein information dataframe. Plot the density of the features and we found that most of the features are skews to left (negatively skewed). Median value of are used to impute the NAs. There is one column with more than half values are NAs, which is "isoprostane_pg_per_mg". The column is removed from the dataframe. 

```{r}
colSums(is.na(ProteinInfo))

p1 <-ggplot()+geom_density(data=data.frame(x=ProteinInfo$isoprostane_pg_per_mg), na.rm = T, aes(x)) + labs(title="Density of isoprostane_pg_per_mg", x ="isoprostane_pg_per_mg", y = "Density")
p2 <-ggplot()+geom_density(data=data.frame(x=ProteinInfo$ihc_tau2_ffpe), na.rm = T, aes(x)) + labs(title="Density of ihc_tau2_ffpe", x ="ihc_tau2_ffpe", y = "Density")
p3 <-ggplot()+geom_density(data=data.frame(x=ProteinInfo$ihc_at8_ffpe), na.rm = T, aes(x)) + labs(title="Density of ihc_at8_ffpe", x ="ihc_at8_ffpe", y = "Density")

multiplot(p1, p2, p3, cols=1)

#replace na with column mean
for (i in seq(ncol(ProteinInfo))) {
  ind <- is.na(ProteinInfo[,i])
  ProteinInfo[ind, i] <- median(ProteinInfo[,i], na.rm = T)
}

#remove the column with 239 N/A
ProteinInfo1 <- ProteinInfo[,-which(colnames(ProteinInfo)=="isoprostane_pg_per_mg")]

sum(colSums(is.na(ProteinInfo1)))
```

3. Merge ProteinInfo with DonorInfo on "donor_id"

```{r}
data1 <- merge(x = DonorInfo.clean, y = ProteinInfo1, by = "donor_id", all = TRUE)
head(data1)
```

#### FPKM and column-sample data
1. Load FPKM data and columns-samples data

```{r}
colsamp <- read.csv("columns-samples.csv", header = TRUE, sep = ",", encoding = "UTF-8")
dim(colsamp)
head(colsamp)
fpkm <- read.csv("fpkm_table_unnormalized.csv", header = TRUE, sep = ",", encoding = "UTF-8")
dim(fpkm)
fpkm[1:5,1:10]

#summary(colsamp[colsamp$structure_name=='temporal neocortex',]$structure_color)
```

2. Remove redundant columns in colsamp. There are only 3 features important in the dataframe which are: "rnaseq_profile_id", "donor_id" and "structure_id".

```{r}
colsamp <- colsamp[,c(1,2,8)]
head(colsamp)
```

3. merge colsamp with data1 on "donor_id" + "structure_id"

```{r}
data2 <- merge(x = colsamp, y = data1, by = c("donor_id", "structure_id"))
dim(data2)
head(data2)
colnames(data2)

# reorder the dataframe based on rnaseq profile id
data2.new <- data2[order(data2[,'rnaseq_profile_id']),]
head(data2.new)

```

4. transpose fpkm

```{r}
fpkm1 <- as.data.frame(t(fpkm))[-1,]
colnames(fpkm1)<-paste("X", fpkm[,1], sep = "")
fpkm1[1:5, 1:10]
```

5. combine fpkm1 with data2.new to produce data.final which is the final data with 377 rows.

```{r}
data3 <- cbind(data2.new, fpkm1)
rownames(data3) <- rownames(fpkm1)

#remove ids
data.final <- data3[,-(1:3)]

data.final[1:5, 1:10]

```


## feature filtering

Save cv and y values before filtering steps for later stage usage

```{r}
# save cv info
cv.377 <- data.filter1['cv']
# save y values
y <- as.matrix(data.filter1['act_demented'])
```

1. remove columns with more than 250 0s. 
The dimension of the filtered data has been reduced from over 50000 to 35193.
About 1.5k features are removed using this rule.

```{r}
# Check if there is any 0 columns
ind.zero <- which(colSums(dataF==0)>250)
data.filter1 <- data.final[, -ind.zero]
sum(colSums(dataFF)==0)
dim(data.filter1)
```

2. remove features using t test
Sepearte the data by its class "act_demented" and conduct a t test for each feature separated by class. If the p-value is small, it means the positive class and negative class are very different. It indicates that the feature is relatively more 'informative'. Filtering the features using the p-value. Features with p-values greater than 0.05 are removed. 

```{r}
# perform a t-test
y.ind = which(names(data.filter1)=='act_demented')

data.byClass <- split(data.filter1[, -y.ind], data.filter1$act_demented)

feature.pvalues <- c()
for(i in 1:(ncol(data.filter1)-1)) {
  feature.pvalues <- c(feature.pvalues, t.test(data.byClass[[1]][,i], data.byClass[[2]][,i])$p.value)
}

names(feature.pvalues) <- colnames(data.filter1[, -y.ind])

ttest.filter.ind <- which(feature.pvalues>0.05)

data.filter2 <- data.filter1[, -y.ind][, -ttest.filter.ind]
dim(data.filter2)
```

#### check that cv and y columns are removed from data

```{r}
which(colnames(data.filter2)=="act_demented")
which(colnames(data.filter2)=="cv")
```

## Clustering 
### PCA

```{r}
data.numeric <- data.filter2

data.pca.scale <- prcomp(data.numeric, scale = T)

pca.df <- as.data.frame(data.pca.scale$x)
pca.df['label']=as.factor(y)
ggplot(pca.df, aes(PC1, PC2, colour = label)) + geom_point() + ggtitle("PC2 vs PC1 by class")
```


```{r}
library(ggplot2)
tot.var <- sum(data.pca.scale$sdev^2)
var.explained <- data.frame(pc = seq(1:length(data.pca.scale$sdev)), var.explained  = data.pca.scale$sdev^2/tot.var ) 
ggplot(var.explained, aes(pc, var.explained)) + geom_point()+ ggtitle("Variance Explained by each PC")
ggplot(var.explained, aes(pc, cumsum(var.explained))) + geom_point()+ ggtitle("Cumsum Variance Explained vs PC No.")
```

## Feature Selection and Modelling

#### Logistic Regression on PCs
#### SVM on PCs
#### Random Forest on PCs

```{r warning=FALSE}
library(e1071)
library(randomForest)

acc <- function(y, y.pred){
  return(sum(y==y.pred)/length(y))
}


lr.acc.train.pc <- c()
lr.acc.val.pc <- c()

svm.acc.train.pc <- c()
svm.acc.val.pc <- c()

rf.acc.train.pc <- c()
rf.acc.val.pc <- c()

pc.no <- seq(10,370,60)

for (pc in pc.no) {
  lr.acc.train <- c()
  lr.acc.val <- c()
  svm.acc.train <- c()
  svm.acc.val <- c()
  rf.acc.train <- c()
  rf.acc.val <- c()
  
  for(i in 1:length(fold)){
    train.df = pca.df[!cv.377==i, c(seq(1,pc),378)]
    val.df = pca.df[cv.377==i, c(seq(1,pc),378)]
    y.ind = which(names(train.df)=='label')
    
    logistic.model <- glm(label ~ .  , data = train.df, family = binomial(link = 'logit'))
    lr.pred.train <- ifelse(predict(logistic.model, train.df) > 0.5, 1, 0)
    lr.pred.val <- ifelse(predict(logistic.model, val.df) > 0.5, 1, 0)
    lr.acc.train <- c(lr.acc.train, acc(lr.pred.train, train.df[,y.ind]))
    lr.acc.val <- c(lr.acc.val, acc(lr.pred.val, val.df[,y.ind]))
    
    svm.model <- svm(x=train.df[,-y.ind], y=train.df[,y.ind],  kernel="linear", type="C-classification", cost = 1)
    svm.pred.train <- predict(svm.model, train.df[,-y.ind])
    svm.pred.val <- predict(svm.model, val.df[,-y.ind])
    svm.acc.train <- c(svm.acc.train, acc(svm.pred.train, train.df[,y.ind]))
    svm.acc.val <- c(svm.acc.val, acc(svm.pred.val, val.df[,y.ind]))
    
    rf.model <- randomForest(label ~ ., data=train.df, importance=TRUE)
    rf.pred.train <- predict(rf.model, train.df)
    rf.pred.val <- predict(rf.model, val.df)
    rf.acc.train <- c(rf.acc.train, acc(rf.pred.train, train.df[,y.ind]))
    rf.acc.val <- c(rf.acc.val, acc(rf.pred.val, val.df[,y.ind]))
    
  }
  lr.acc.train.pc <- c(lr.acc.train.pc, mean(lr.acc.train))
  lr.acc.val.pc <- c(lr.acc.val.pc, mean(lr.acc.val))
  svm.acc.train.pc <- c(svm.acc.train.pc, mean(svm.acc.train))
  svm.acc.val.pc <- c(svm.acc.val.pc, mean(svm.acc.val))
  rf.acc.train.pc <- c(rf.acc.train.pc, mean(rf.acc.train))
  rf.acc.val.pc <- c(rf.acc.val.pc, mean(rf.acc.val))
}

```

```{r}
plot(pc.no, lr.acc.val.pc)
pc.no[which.max(lr.acc.val.pc)]
max(lr.acc.val.pc)

plot(pc.no, svm.acc.val.pc)
pc.no[which.max(svm.acc.val.pc)]
max(svm.acc.val.pc)

plot(pc.no, rf.acc.val.pc)
pc.no[which.max(rf.acc.val.pc)]
max(rf.acc.val.pc)
```

#### Feature selection using t-test and p-value

```{r}
data.byClass <- split(data.numeric, y)

feature.pvalues <- c()
for(i in 1:(ncol(data.numeric))) {
  feature.pvalues <- c(feature.pvalues, t.test(data.byClass[[1]][,i], data.byClass[[2]][,i])$p.value)
}

names(feature.pvalues) <- colnames(data.numeric)

ttest.feature.ind.ordered = order(feature.pvalues)

data.ttest <- data.numeric[,ttest.feature.ind.ordered]

data.ttest['label'] = as.factor(y)
```


#### Logistic Regression using features selected by t-test

```{r}
y.ind = which(names(data.ttest)=='label')
feature.no <- seq(1,20)

lr.acc.train.t <- c()
lr.acc.val.t <- c()
svm.acc.train.t <- c()
svm.acc.val.t <- c()
rf.acc.train.t <- c()
rf.acc.val.t <- c()


for (f in feature.no) {
  lr.acc.train <- c()
  lr.acc.val <- c()
  svm.acc.train <- c()
  svm.acc.val <- c()
  rf.acc.train <- c()
  rf.acc.val <- c()
  
  for(i in 1:length(fold)){
    train.df = pca.df[!cv.377==i, c(seq(1,f),16836)]
    val.df = pca.df[cv.377==i, c(seq(1,f),16836)]
    y.ind = which(names(train.df)=='label')
    
    logistic.model <- glm(label ~ .  , data = train.df, family = binomial(link = 'logit'))
    lr.pred.train <- ifelse(predict(logistic.model, train.df) > 0.5, 1, 0)
    lr.pred.val <- ifelse(predict(logistic.model, val.df) > 0.5, 1, 0)
    lr.acc.train <- c(lr.acc.train, acc(lr.pred.train, train.df[,y.ind]))
    lr.acc.val <- c(lr.acc.val, acc(lr.pred.val, val.df[,y.ind]))
    
    svm.model <- svm(x=train.df[,-y.ind], y=train.df[,y.ind],  kernel="linear", type="C-classification", cost = 1)
    svm.pred.train <- predict(svm.model, train.df[,-y.ind])
    svm.pred.val <- predict(svm.model, val.df[,-y.ind])
    svm.acc.train <- c(svm.acc.train, acc(svm.pred.train, train.df[,y.ind]))
    svm.acc.val <- c(svm.acc.val, acc(svm.pred.val, val.df[,y.ind]))
    
    rf.model <- randomForest(label ~ ., data=train.df, importance=TRUE, mtry=round(f^0.5))
    rf.pred.train <- predict(rf.model, train.df)
    rf.pred.val <- predict(rf.model, val.df)
    rf.acc.train <- c(rf.acc.train, acc(rf.pred.train, train.df[,y.ind]))
    rf.acc.val <- c(rf.acc.val, acc(rf.pred.val, val.df[,y.ind]))
    
  }
  lr.acc.train.t <- c(lr.acc.train.t, mean(lr.acc.train))
  lr.acc.val.t <- c(lr.acc.val.t, mean(lr.acc.val))
  svm.acc.train.t <- c(svm.acc.train.t, mean(svm.acc.train))
  svm.acc.val.t <- c(svm.acc.val.t, mean(svm.acc.val))
  rf.acc.train.t <- c(rf.acc.train.t, mean(rf.acc.train))
  rf.acc.val.t <- c(rf.acc.val.t, mean(rf.acc.val))
}
```


```{r}
plot(feature.no, lr.acc.val.t)
cat('feature no for logistic regression')
feature.no[which.max(lr.acc.val.t)]
max(lr.acc.val.t)

plot(feature.no, svm.acc.val.t, type = 'l')
cat('feature no for linear kernel')
feature.no[which.max(svm.acc.val.t)]
max(svm.acc.val.t)

plot(feature.no, rf.acc.val.t)
cat('feature no for random forest')
feature.no[which.max(rf.acc.val.t)]
max(rf.acc.val.t)
```


#### Forward wrapper approach for feature selection

```{r}
selectFeature <- function(df, features, mode) {
  ## identify a feature to be selected
  current.best.accuracy <- -Inf
  selected.i <- NULL
  for(i in 1:(ncol(df)-1)) {
    current.f <- colnames(df)[i]
    if(!current.f %in% features) {
      test.acc = rep(0,10)
      for(cv in 1:length(fold)){
        train = df[!cv.377==cv, c(features, current.f)]
        test = df[cv.377==cv, c(features, current.f)]
        
        if(mode == "svm"){
          y.ind = which(colnames(train)=='label')
          svm.model <- svm(x=train[,-y.ind], y=train[,y.ind],  kernel="linear", type="C-classification", cost = 0.1)
          model <- predict(svm.model, test[,-y.ind])
        }
        else if(mode == "lr"){
          logistic.model <- glm(label ~ .  , data = train, family = binomial(link = 'logit'))
          model <- ifelse(predict(logistic.model, test) > 0.5, 1, 0)
        }
        
        test.acc[cv] <- acc(test$label, model)
      }
      if(mean(test.acc) > current.best.accuracy) {
        current.best.accuracy <- mean(test.acc)
        selected.i <- colnames(df)[i]
      }
    }
  }
  return(list(selected.i, current.best.accuracy))
}
```


#### Forward stepwise + PCA + Logistic Regression

```{r warning=FALSE}
features.pca.lr <- c('PC1', 'label')
forward.pca.lr.acc <- c()

for (j in 2:50) {
  ret <- selectFeature(pca.df, features.pca.lr, "lr")
  selected.i <- ret[[1]]
  current.best.acc <- ret[[2]]
  cat(j, selected.i, ': ', current.best.acc, '\n')

  features.pca.lr <- c(features.pca.lr, selected.i)
  
  forward.pca.lr.acc <- c(forward.pca.lr.acc, current.best.acc)
}

plot(seq(2,50), forward.pca.lr.acc)
```

#### Forward stepwise + PCA + SVM

```{r}
features.pca.svm <- c('PC1', 'label')
forward.pca.svm.acc <- c()

for (j in 2:30) {
  ret <- selectFeature(pca.df, features.pca.svm, "svm")
  selected.i <- ret[[1]]
  current.best.acc <- ret[[2]]
  cat(j, selected.i, ': ', current.best.acc, '\n')

  features.pca.svm <- c(features.pca.svm, selected.i)
  
  forward.pca.svm.acc <- c(forward.pca.svm.acc, current.best.acc)
}

plot(seq(2:30), forward.pca.svm.acc)

```

#### Forward stepwise + t-test + Logistic Regression

```{r}
features.ttest.lr = c('label', names(data.ttest)[1])
forward.t.lr.acc <- c()

for (j in 2:30) {
  ret <- selectFeature(data.ttest[,c(seq(1,400),16836)], features.ttest.lr, "lr")
  selected.i <- ret[[1]]
  current.best.acc <- ret[[2]]
  cat(j, selected.i, ': ', current.best.acc, '\n')

  features.ttest.lr <- c(features.ttest.lr, selected.i)
  
  forward.t.lr.acc <- c(forward.t.lr.acc, current.best.acc)
}

plot(seq(2,30), forward.t.lr.acc)
```

#### Forward stepwise + t-test + SVM

```{r}
features.ttest.svm = c('label', names(data.ttest)[1])

forward.t.svm.acc <- c()

# select the 2 to 10 best features using knn as a wrapper classifier
for (j in 2:50) {
  ret <- selectFeature(data.ttest[,c(seq(1,400),16836)], features.ttest.svm, "svm")
  selected.i <- ret[[1]]
  current.best.acc <- ret[[2]]
  cat(j, selected.i, ': ', current.best.acc, '\n')

  # add the best feature from current run
  features.ttest.svm <- c(features.ttest.svm, selected.i)
  
  forward.t.svm.acc <- c(forward.t.svm.acc, current.best.acc)
}

plot(seq(2:50), forward.t.svm.acc)

```






# Section 2
## Do gene expression and protein quantification sex dependent?

```{r}
sex.data <- data.filter1[, -which(colnames(data.filter1) %in% colnames(DonorInfo))]
sex <- data.filter1$sex
```

```{r}
data.sex.byClass <- split(sex.data, sex)

feature.pvalues <- c()
for(i in 1:(ncol(sex.data))) {
  feature.pvalues <- c(feature.pvalues, t.test(data.sex.byClass[[1]][,i], data.sex.byClass[[2]][,i])$p.value)
}

names(feature.pvalues) <- colnames(sex.data)

ttest.filter.ind <- which(feature.pvalues>0.05)

sex.filtered.data <- sex.data[, -ttest.filter.ind]
dim(sex.filtered.data)
```


```{r}
pca.sex.data <- prcomp(sex.filtered.data, scale = T)

pca.sex.df <- as.data.frame(pca.sex.data$x)
pca.sex.df['label']=as.factor(sex)
ggplot(pca.sex.df, aes(PC1, PC2, colour = label)) + geom_point()
```

```{r warning=FALSE}
features.sex.pca.lr <- c('PC1', 'label')
forward.sex.pca.lr.acc <- c()

for (j in 2:10) {
  ret <- selectFeature(pca.sex.df, features.sex.pca.lr, "lr")
  selected.i <- ret[[1]]
  current.best.acc <- ret[[2]]
  cat(j, selected.i, ': ', current.best.acc, '\n')

  features.sex.pca.lr <- c(features.sex.pca.lr, selected.i)
  
  forward.sex.pca.lr.acc <- c(forward.sex.pca.lr.acc, current.best.acc)
}

# plot(seq(2,10), forward.sex.pca.lr.acc)
```

```{r}
ttest.feature.ind.ordered = order(feature.pvalues)
data.ttest <- sex.data[,ttest.feature.ind.ordered]
data.ttest['label'] = as.factor(sex)
```

# t-test + SVM + Forward stepwise
```{r}
features.ttest.svm = c('label')

svm.forward.acc <- c()

# select the 2 to 10 best features using knn as a wrapper classifier
for (j in 1:3) {
  ret <- selectFeature(data.ttest[,c(seq(1,400),35188)], features.ttest.svm, "svm")
  selected.i <- ret[[1]]
  current.best.acc <- ret[[2]]
  cat(j, selected.i, ': ', current.best.acc, '\n')

  # add the best feature from current run
  features.ttest.svm <- c(features.ttest.svm, selected.i)
  
  svm.forward.acc <- c(svm.forward.acc, current.best.acc)
}

plot(seq(1:3), svm.forward.acc)

```




